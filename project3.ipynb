{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ffdeb4",
   "metadata": {},
   "source": [
    "# Parte 3: Implement an Inverted Index and Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc67efc",
   "metadata": {},
   "source": [
    "https://rosettacode.org/wiki/Inverted_index#Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "599b2e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33be50f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Spacy Language model\n",
    "sp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ece467fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('tfidf.json', 'r') as outfile:\n",
    "    summaries = json.load(outfile)\n",
    "\n",
    "with open('vocabulario.json', 'r') as outfile:\n",
    "    vocab = json.load(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0b451a",
   "metadata": {},
   "source": [
    "### Construcci√≥n de fichero invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c4dbf63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HIV/AIDS', 0.01586273031272535),\n",
       " ('Spanish flu', 0.020235699209746934),\n",
       " ('Superspreader', 0.027127567781182485),\n",
       " ('Swine influenza', 0.023693698441792296)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    inverted_index[word] = []\n",
    "    \n",
    "    for doc in summaries:\n",
    "        # for each word in corpus vocabulary list all articles\n",
    "        # it occurs in and this word's TfIdf score for this article\n",
    "        if doc['tf_idf'][i]!=0:\n",
    "            inverted_index[word].append((doc['title'], doc['tf_idf'][i])) \n",
    "\n",
    "# Now you have a lookup table of all articles that have a particular keyword\n",
    "# lets request a list of articles with the word \"coronavirus\" in them\n",
    "inverted_index[\"illness\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b1df2",
   "metadata": {},
   "source": [
    "### Search inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00f6b36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse the tokenizer from Milestone 1 to tokenize search queries\n",
    "\n",
    "def tokenizer(document):\n",
    "    text_lowercased = sp(document.lower())\n",
    "    tokens_without_stopwords = [word for word \n",
    "                     in text_lowercased \n",
    "                     if not word.is_stop \n",
    "                     and not word.is_punct\n",
    "                     and len(word.dep_.strip())!=0]   \n",
    "    \n",
    "    token_lemmatized = [token.lemma_ \n",
    "               for token\n",
    "               in tokens_without_stopwords]\n",
    "    \n",
    "    return token_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d3695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a search function to search the inverted index\n",
    "\n",
    "def search(query, index = inverted_index):\n",
    "    \n",
    "    query_tokens = tokenizer(query)\n",
    "    \n",
    "    # Lookup all query tokens in the inverted index\n",
    "    # and build an list of articles that have them\n",
    "    # The results should be a list of tuples with article titles and TfIdf scores\n",
    "    newlist = []\n",
    "    for token in query_tokens:\n",
    "        newlist.extend(inverted_index[token])\n",
    "    \n",
    "    \n",
    "    # create a dictionary with compound TfIdf scores \n",
    "    # to take into account that an article can include multiple keywords\n",
    "    # from your query\n",
    "    \n",
    "    output = defaultdict(int) \n",
    "\n",
    "    for k, v in newlist: \n",
    "        output[k] += v \n",
    "    results = [(x, y) for x, y in output.items()]\n",
    "    \n",
    "    # sort search results by their TfIdf scores\n",
    "    return sorted(results, key = lambda x: x[1], reverse=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57d48b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Johns Hopkins Center for Health Security (abbreviated CHS; previously the UPMC Center for Health Security, the Center for Biosecurity of UPMC, and the Johns Hopkins Center for Civilian Biodefense Strategies) is an independent, nonprofit organization of the Johns Hopkins Bloomberg School of Public Health, and part of the Environmental Health and Engineering department. It is concerned with the areas of health consequences from epidemics and disasters as well as averting biological weapons development, and implications of biosecurity for the bioeconomy. It is a think tank that does policy research and gives policy recommendations to the United States government as well as the World Health Organization and the UN Biological Weapons Convention.\n"
     ]
    }
   ],
   "source": [
    "# Time to check how well this search performs for multi-word queries:\n",
    "title, score = search(query = \"world health organization\")[0]\n",
    "for s in summaries:\n",
    "    if s[\"title\"] == title:\n",
    "        print(s[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "516ebbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Virus', 0.069046255402524),\n",
       " ('Plague of Cyprian', 0.06586828120547401),\n",
       " ('Crimson Contagion', 0.03535073692697718),\n",
       " ('Disease X', 0.03487302426580182),\n",
       " ('Viral load', 0.03468553488802869),\n",
       " ('Swine influenza', 0.0326658708312574),\n",
       " ('Science diplomacy and pandemics', 0.027580100617865987),\n",
       " ('HIV/AIDS in Yunnan', 0.024577179006374617),\n",
       " ('HIV/AIDS', 0.01457968246140867),\n",
       " ('Spanish flu', 0.013949209706320728),\n",
       " ('Epidemiology of HIV/AIDS', 0.007964826529843625),\n",
       " ('COVID-19 pandemic', 0.0055141106745071255)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search(query = \"Ebola virus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d79f17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
